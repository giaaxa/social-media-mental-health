{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Exploratory Data Analysis & Hypothesis Testing\n",
    "\n",
    "## Social Media and Mental Health Dataset\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA) and statistical hypothesis testing on the cleaned `smmh_clean.csv` dataset. The dataset contains 481 survey responses exploring the relationship between social media usage patterns (time spent, purposeless scrolling, comparison behaviour, validation-seeking) and self-reported wellbeing indicators (low mood frequency, sleep issues, concentration difficulties).\n",
    "\n",
    "### Important: What We Can and Cannot Conclude\n",
    "\n",
    "**This is observational survey data.** All findings represent **associations**, not causal relationships. We cannot conclude that social media *causes* mental health outcomes—only that certain usage patterns tend to co-occur with certain wellbeing indicators in this sample. Factors like personality, life circumstances, and reverse causality (e.g., people with low mood may use social media more) cannot be ruled out.\n",
    "\n",
    "### Outputs Generated\n",
    "- `reports/eda_summary.md` — Key findings and notable distributions\n",
    "- `reports/hypothesis_results.csv` — Statistical test results\n",
    "- `reports/figures/*.png` — Publication-ready plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up paths - .parent goes up one level from jupyter_notebooks/ to project root\n",
    "project_root = Path.cwd().parent\n",
    "data_path = project_root / \"data\" / \"processed\" / \"v1\" / \"smmh_clean.csv\"\n",
    "reports_path = project_root / \"reports\"\n",
    "figures_path = reports_path / \"figures\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "figures_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Data file exists: {data_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib configuration for consistent, clean plots\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'figure.dpi': 100,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "# Colour palette (accessible, not seaborn)\n",
    "COLORS = {\n",
    "    'primary': '#2E86AB',\n",
    "    'secondary': '#A23B72',\n",
    "    'tertiary': '#F18F01',\n",
    "    'quaternary': '#C73E1D',\n",
    "    'neutral': '#3B3B3B',\n",
    "    'light': '#E8E8E8',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/giaaxa/data/processed/v1/smmh_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_full = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_full.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_full.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Filter to analysis subset (social media users only)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.12/lib/python/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/giaaxa/data/processed/v1/smmh_clean.csv'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_full = pd.read_csv(data_path)\n",
    "print(f\"Full dataset: {df_full.shape[0]} rows, {df_full.shape[1]} columns\")\n",
    "\n",
    "# Filter to analysis subset (social media users only)\n",
    "df = df_full[df_full[\"include_in_analysis\"] == True].copy()\n",
    "print(f\"Analysis subset: {df.shape[0]} rows (excluded {df_full.shape[0] - df.shape[0]} non-SM users)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column groups for easy reference\n",
    "LIKERT_COLS = [\n",
    "    \"purposeless_use\", \"distracted_when_busy\", \"restless_without_sm\",\n",
    "    \"easily_distracted\", \"worries_bother\", \"difficulty_concentrating\",\n",
    "    \"compare_to_successful\", \"comparison_feelings\", \"seek_validation\",\n",
    "    \"low_mood_freq\", \"interest_fluctuation\", \"sleep_issues\"\n",
    "]\n",
    "\n",
    "PLATFORM_COLS = [\n",
    "    \"platform_facebook\", \"platform_twitter\", \"platform_instagram\",\n",
    "    \"platform_youtube\", \"platform_snapchat\", \"platform_discord\",\n",
    "    \"platform_reddit\", \"platform_pinterest\", \"platform_tiktok\"\n",
    "]\n",
    "\n",
    "WELLBEING_COLS = [\"low_mood_freq\", \"sleep_issues\", \"worries_bother\", \"difficulty_concentrating\"]\n",
    "\n",
    "BEHAVIOUR_COLS = [\"purposeless_use\", \"distracted_when_busy\", \"restless_without_sm\",\n",
    "                  \"compare_to_successful\", \"seek_validation\"]\n",
    "\n",
    "# Ordered time bands (for proper sorting)\n",
    "TIME_BAND_ORDER = [\n",
    "    \"Less than an Hour\",\n",
    "    \"Between 1 and 2 hours\",\n",
    "    \"Between 2 and 3 hours\",\n",
    "    \"Between 3 and 4 hours\",\n",
    "    \"Between 4 and 5 hours\",\n",
    "    \"More than 5 hours\"\n",
    "]\n",
    "\n",
    "# Convert to ordered categorical\n",
    "df[\"daily_time_band\"] = pd.Categorical(df[\"daily_time_band\"], categories=TIME_BAND_ORDER, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Quality & Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Shape\n",
    "print(f\"\\nDataset shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "\n",
    "# Duplicates\n",
    "n_duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {n_duplicates}\")\n",
    "\n",
    "# Missingness\n",
    "print(\"\\nMissingness by column:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\"missing_count\": missing, \"missing_pct\": missing_pct})\n",
    "missing_df = missing_df[missing_df[\"missing_count\"] > 0]\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"  No missing values in analysis columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Likert scales are within 1-5\n",
    "print(\"\\nLikert scale validation (must be 1-5):\")\n",
    "for col in LIKERT_COLS:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    status = \"OK\" if (min_val >= 1 and max_val <= 5) else \"FAIL\"\n",
    "    print(f\"  {col}: [{min_val}-{max_val}] {status}\")\n",
    "    assert min_val >= 1 and max_val <= 5, f\"Likert validation failed for {col}\"\n",
    "\n",
    "print(\"\\n All Likert columns validated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution check\n",
    "print(\"\\nAge distribution:\")\n",
    "print(df[\"age\"].describe())\n",
    "print(f\"\\nAge bands:\")\n",
    "print(df[\"age_band\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time band distribution\n",
    "print(\"\\nDaily time spent on social media:\")\n",
    "print(df[\"daily_time_band\"].value_counts().reindex(TIME_BAND_ORDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform count distribution\n",
    "print(\"\\nNumber of platforms used:\")\n",
    "print(df[\"platform_count\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics for key variables\n",
    "print(\"Descriptive statistics for Likert-scale variables (1-5):\")\n",
    "df[LIKERT_COLS].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DEMOGRAPHIC SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nTotal respondents (SM users): {len(df)}\")\n",
    "print(f\"\\nGender distribution (grouped for privacy):\")\n",
    "print(df[\"gender_grouped\"].value_counts())\n",
    "\n",
    "print(f\"\\nAge band distribution:\")\n",
    "print(df[\"age_band\"].value_counts())\n",
    "\n",
    "print(f\"\\nRelationship status:\")\n",
    "print(df[\"relationship_status\"].value_counts())\n",
    "\n",
    "print(f\"\\nOccupation status:\")\n",
    "print(df[\"occupation_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Platform Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform usage counts\n",
    "platform_usage = {}\n",
    "for col in PLATFORM_COLS:\n",
    "    platform_name = col.replace(\"platform_\", \"\").title()\n",
    "    count = df[col].sum()\n",
    "    pct = count / len(df) * 100\n",
    "    platform_usage[platform_name] = {\"count\": count, \"pct\": round(pct, 1)}\n",
    "\n",
    "platform_df = pd.DataFrame(platform_usage).T.sort_values(\"count\", ascending=False)\n",
    "print(\"Platform usage (% of respondents):\")\n",
    "print(platform_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Platform usage\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "platforms = platform_df.index.tolist()\n",
    "counts = platform_df[\"pct\"].values\n",
    "\n",
    "bars = ax.barh(platforms, counts, color=COLORS[\"primary\"], edgecolor=\"white\")\n",
    "ax.set_xlabel(\"Percentage of Respondents (%)\")\n",
    "ax.set_ylabel(\"Platform\")\n",
    "ax.set_title(\"Social Media Platform Usage Among Respondents\")\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, pct in zip(bars, counts):\n",
    "    ax.text(pct + 1, bar.get_y() + bar.get_height()/2, f\"{pct:.0f}%\", \n",
    "            va=\"center\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"platform_usage.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** YouTube (86%) and Facebook (85%) are the most commonly used platforms, followed by Instagram (75%). TikTok usage is relatively lower (20%), though this may reflect the survey's demographic composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Outcome Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: Distribution of wellbeing indicators\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "wellbeing_labels = {\n",
    "    \"low_mood_freq\": \"Low Mood Frequency\",\n",
    "    \"sleep_issues\": \"Sleep Issues\",\n",
    "    \"worries_bother\": \"Bothered by Worries\",\n",
    "    \"difficulty_concentrating\": \"Difficulty Concentrating\"\n",
    "}\n",
    "\n",
    "for i, col in enumerate(WELLBEING_COLS):\n",
    "    ax = axes[i]\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Count frequencies for each level (1-5)\n",
    "    counts = data.value_counts().sort_index()\n",
    "    \n",
    "    ax.bar(counts.index, counts.values, color=COLORS[\"secondary\"], edgecolor=\"white\", width=0.7)\n",
    "    ax.set_xlabel(\"Response (1=Low, 5=High)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"Distribution: {wellbeing_labels[col]}\")\n",
    "    ax.set_xticks([1, 2, 3, 4, 5])\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = data.mean()\n",
    "    ax.axvline(mean_val, color=COLORS[\"quaternary\"], linestyle=\"--\", linewidth=2, label=f\"Mean: {mean_val:.2f}\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\"Distribution of Wellbeing Indicators (1-5 Scale)\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"wellbeing_distributions.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** The wellbeing indicators show varied distributions. Low mood frequency and sleep issues have relatively even distributions across the 1-5 scale, while \"bothered by worries\" tends to cluster at higher values, suggesting this sample reports moderate-to-high worry levels overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time band distribution (histogram-style bar chart)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "time_counts = df[\"daily_time_band\"].value_counts().reindex(TIME_BAND_ORDER)\n",
    "time_labels = [\"<1h\", \"1-2h\", \"2-3h\", \"3-4h\", \"4-5h\", \">5h\"]\n",
    "\n",
    "bars = ax.bar(range(len(time_labels)), time_counts.values, color=COLORS[\"tertiary\"], edgecolor=\"white\")\n",
    "ax.set_xticks(range(len(time_labels)))\n",
    "ax.set_xticklabels(time_labels)\n",
    "ax.set_xlabel(\"Daily Time Spent on Social Media\")\n",
    "ax.set_ylabel(\"Number of Respondents\")\n",
    "ax.set_title(\"Distribution of Daily Social Media Usage Time\")\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, time_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, str(count),\n",
    "            ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"time_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** The majority of respondents spend 2+ hours daily on social media, with \"More than 5 hours\" being the most common category (24%). Only 7% report using social media for less than an hour per day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Correlation Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation matrix for ordinal Likert variables\n",
    "# (Spearman is appropriate for ordinal data)\n",
    "\n",
    "corr_cols = BEHAVIOUR_COLS + WELLBEING_COLS + [\"daily_hours_midpoint\", \"platform_count\"]\n",
    "corr_matrix = df[corr_cols].corr(method=\"spearman\")\n",
    "\n",
    "print(\"Spearman correlation matrix (behaviour + wellbeing variables):\")\n",
    "corr_matrix.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of correlations (using matplotlib, not seaborn)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create heatmap\n",
    "im = ax.imshow(corr_matrix.values, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"auto\")\n",
    "\n",
    "# Set ticks and labels\n",
    "ax.set_xticks(range(len(corr_cols)))\n",
    "ax.set_yticks(range(len(corr_cols)))\n",
    "\n",
    "# Shortened labels for readability\n",
    "short_labels = [\n",
    "    \"Purposeless\", \"Distracted\", \"Restless\", \"Compare\", \"Validation\",\n",
    "    \"Low Mood\", \"Sleep Issues\", \"Worries\", \"Concentration\",\n",
    "    \"Hours/Day\", \"# Platforms\"\n",
    "]\n",
    "ax.set_xticklabels(short_labels, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(short_labels)\n",
    "\n",
    "# Add correlation values as text\n",
    "for i in range(len(corr_cols)):\n",
    "    for j in range(len(corr_cols)):\n",
    "        val = corr_matrix.values[i, j]\n",
    "        color = \"white\" if abs(val) > 0.5 else \"black\"\n",
    "        ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\", color=color, fontsize=8)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "cbar.set_label(\"Spearman Correlation (rho)\")\n",
    "\n",
    "ax.set_title(\"Correlation Matrix: Usage Behaviours vs Wellbeing Indicators\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"correlation_heatmap.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** Several moderate positive correlations exist between usage behaviours and wellbeing concerns. Notably, `compare_to_successful` shows correlations with multiple wellbeing indicators, as does `purposeless_use`. The wellbeing indicators themselves are moderately inter-correlated, which is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Hypothesis Testing\n",
    "\n",
    "### Statistical Approach\n",
    "- **Kruskal-Wallis H-test**: Non-parametric test for comparing distributions across multiple groups (used when outcome is ordinal)\n",
    "- **Spearman correlation**: Non-parametric measure of monotonic association between two ordinal variables\n",
    "- **Effect sizes**: Epsilon squared (ε²) for Kruskal-Wallis; Spearman's rho itself serves as effect size for correlations\n",
    "\n",
    "### Effect Size Interpretation Guidelines\n",
    "| Measure | Small | Medium | Large |\n",
    "|---------|-------|--------|-------|\n",
    "| Spearman rho | 0.10 | 0.30 | 0.50 |\n",
    "| Epsilon squared | 0.01 | 0.06 | 0.14 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for hypothesis testing\n",
    "\n",
    "def epsilon_squared(h_stat, n, k):\n",
    "    \"\"\"Calculate epsilon squared effect size for Kruskal-Wallis test.\n",
    "    \n",
    "    Formula: ε² = H / (n - 1)\n",
    "    Where H is the Kruskal-Wallis H statistic and n is total sample size.\n",
    "    \"\"\"\n",
    "    return h_stat / (n - 1)\n",
    "\n",
    "\n",
    "def interpret_rho(rho):\n",
    "    \"\"\"Interpret Spearman correlation magnitude.\"\"\"\n",
    "    abs_rho = abs(rho)\n",
    "    if abs_rho < 0.10:\n",
    "        return \"negligible\"\n",
    "    elif abs_rho < 0.30:\n",
    "        return \"small\"\n",
    "    elif abs_rho < 0.50:\n",
    "        return \"moderate\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "\n",
    "def interpret_epsilon(eps):\n",
    "    \"\"\"Interpret epsilon squared effect size.\"\"\"\n",
    "    if eps < 0.01:\n",
    "        return \"negligible\"\n",
    "    elif eps < 0.06:\n",
    "        return \"small\"\n",
    "    elif eps < 0.14:\n",
    "        return \"moderate\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "\n",
    "def run_spearman_test(df, var1, var2):\n",
    "    \"\"\"Run Spearman correlation test and return results dict.\"\"\"\n",
    "    data = df[[var1, var2]].dropna()\n",
    "    rho, p_value = stats.spearmanr(data[var1], data[var2])\n",
    "    return {\n",
    "        \"n\": len(data),\n",
    "        \"statistic\": rho,\n",
    "        \"p_value\": p_value,\n",
    "        \"effect_size_name\": \"Spearman rho\",\n",
    "        \"effect_size_value\": rho,\n",
    "        \"interpretation\": interpret_rho(rho)\n",
    "    }\n",
    "\n",
    "\n",
    "def run_kruskal_test(df, group_col, outcome_col):\n",
    "    \"\"\"Run Kruskal-Wallis test and return results dict.\"\"\"\n",
    "    data = df[[group_col, outcome_col]].dropna()\n",
    "    groups = [group[outcome_col].values for name, group in data.groupby(group_col)]\n",
    "    \n",
    "    # Filter out empty groups\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    \n",
    "    h_stat, p_value = stats.kruskal(*groups)\n",
    "    n = len(data)\n",
    "    k = len(groups)\n",
    "    eps_sq = epsilon_squared(h_stat, n, k)\n",
    "    \n",
    "    return {\n",
    "        \"n\": n,\n",
    "        \"statistic\": h_stat,\n",
    "        \"p_value\": p_value,\n",
    "        \"effect_size_name\": \"epsilon_squared\",\n",
    "        \"effect_size_value\": eps_sq,\n",
    "        \"interpretation\": interpret_epsilon(eps_sq)\n",
    "    }\n",
    "\n",
    "\n",
    "# Store all hypothesis results\n",
    "hypothesis_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1: Higher daily time spent is associated with higher low mood frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H1: Kruskal-Wallis test - low_mood_freq across daily_time_band groups\n",
    "h1_result = run_kruskal_test(df, \"daily_time_band\", \"low_mood_freq\")\n",
    "\n",
    "print(\"H1: Daily time spent vs Low mood frequency\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test: Kruskal-Wallis H-test\")\n",
    "print(f\"n = {h1_result['n']}\")\n",
    "print(f\"H-statistic = {h1_result['statistic']:.3f}\")\n",
    "print(f\"p-value = {h1_result['p_value']:.4f}\")\n",
    "print(f\"Effect size (ε²) = {h1_result['effect_size_value']:.4f} ({h1_result['interpretation']})\")\n",
    "\n",
    "if h1_result['p_value'] < 0.05:\n",
    "    print(\"\\n=> Statistically significant association detected.\")\n",
    "else:\n",
    "    print(\"\\n=> No statistically significant association at α=0.05.\")\n",
    "\n",
    "hypothesis_results.append({\n",
    "    \"hypothesis_id\": \"H1\",\n",
    "    \"outcome\": \"low_mood_freq\",\n",
    "    \"predictor\": \"daily_time_band\",\n",
    "    \"test_used\": \"Kruskal-Wallis\",\n",
    "    **h1_result\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H1 Plot: Box plot of low_mood_freq by daily_time_band\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Prepare data for box plot\n",
    "box_data = [df[df[\"daily_time_band\"] == band][\"low_mood_freq\"].dropna().values \n",
    "            for band in TIME_BAND_ORDER]\n",
    "time_labels = [\"<1h\", \"1-2h\", \"2-3h\", \"3-4h\", \"4-5h\", \">5h\"]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=time_labels, patch_artist=True)\n",
    "\n",
    "# Style the boxes\n",
    "for patch in bp[\"boxes\"]:\n",
    "    patch.set_facecolor(COLORS[\"primary\"])\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Add mean markers\n",
    "means = [np.mean(d) for d in box_data]\n",
    "ax.scatter(range(1, 7), means, color=COLORS[\"quaternary\"], marker=\"D\", s=50, zorder=3, label=\"Mean\")\n",
    "\n",
    "ax.set_xlabel(\"Daily Time Spent on Social Media\")\n",
    "ax.set_ylabel(\"Low Mood Frequency (1-5)\")\n",
    "ax.set_title(\"H1: Low Mood Frequency by Daily Social Media Time\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 5.5)\n",
    "\n",
    "# Add sample sizes\n",
    "for i, (label, data) in enumerate(zip(time_labels, box_data), 1):\n",
    "    ax.text(i, 0.7, f\"n={len(data)}\", ha=\"center\", fontsize=9, color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"h1_low_mood_by_time_band.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** There appears to be a trend where respondents who spend more time on social media report slightly higher low mood frequency, though the effect size is small. The median and mean values increase gradually from the lowest to highest time bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2: More purposeless_use is associated with higher low_mood_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2: Spearman correlation - purposeless_use vs low_mood_freq\n",
    "h2_result = run_spearman_test(df, \"purposeless_use\", \"low_mood_freq\")\n",
    "\n",
    "print(\"H2: Purposeless use vs Low mood frequency\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test: Spearman correlation\")\n",
    "print(f\"n = {h2_result['n']}\")\n",
    "print(f\"Spearman rho = {h2_result['statistic']:.3f}\")\n",
    "print(f\"p-value = {h2_result['p_value']:.4e}\")\n",
    "print(f\"Effect size interpretation: {h2_result['interpretation']}\")\n",
    "\n",
    "if h2_result['p_value'] < 0.05:\n",
    "    direction = \"positive\" if h2_result['statistic'] > 0 else \"negative\"\n",
    "    print(f\"\\n=> Statistically significant {direction} association detected.\")\n",
    "else:\n",
    "    print(\"\\n=> No statistically significant association at α=0.05.\")\n",
    "\n",
    "hypothesis_results.append({\n",
    "    \"hypothesis_id\": \"H2\",\n",
    "    \"outcome\": \"low_mood_freq\",\n",
    "    \"predictor\": \"purposeless_use\",\n",
    "    \"test_used\": \"Spearman correlation\",\n",
    "    **h2_result\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2 Plot: Scatter plot with jitter\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Add jitter to see overlapping points\n",
    "x = df[\"purposeless_use\"].values + np.random.uniform(-0.15, 0.15, len(df))\n",
    "y = df[\"low_mood_freq\"].values + np.random.uniform(-0.15, 0.15, len(df))\n",
    "\n",
    "ax.scatter(x, y, alpha=0.4, color=COLORS[\"primary\"], edgecolor=\"none\", s=40)\n",
    "\n",
    "# Add trend line (binned means)\n",
    "binned_means = df.groupby(\"purposeless_use\")[\"low_mood_freq\"].mean()\n",
    "ax.plot(binned_means.index, binned_means.values, color=COLORS[\"quaternary\"], \n",
    "        linewidth=3, marker=\"o\", markersize=10, label=\"Mean by level\")\n",
    "\n",
    "ax.set_xlabel(\"Purposeless Use (1-5)\")\n",
    "ax.set_ylabel(\"Low Mood Frequency (1-5)\")\n",
    "ax.set_title(f\"H2: Purposeless Use vs Low Mood Frequency (rho={h2_result['statistic']:.2f})\")\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"h2_purposeless_vs_mood.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** There is a moderate positive correlation between purposeless social media use and low mood frequency. Respondents who report more frequent \"aimless scrolling\" also tend to report more frequent low mood. This is one of the stronger associations in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H3: Higher compare_to_successful is associated with higher low_mood_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H3: Spearman correlation - compare_to_successful vs low_mood_freq\n",
    "h3_result = run_spearman_test(df, \"compare_to_successful\", \"low_mood_freq\")\n",
    "\n",
    "print(\"H3: Comparison to successful people vs Low mood frequency\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test: Spearman correlation\")\n",
    "print(f\"n = {h3_result['n']}\")\n",
    "print(f\"Spearman rho = {h3_result['statistic']:.3f}\")\n",
    "print(f\"p-value = {h3_result['p_value']:.4e}\")\n",
    "print(f\"Effect size interpretation: {h3_result['interpretation']}\")\n",
    "\n",
    "if h3_result['p_value'] < 0.05:\n",
    "    direction = \"positive\" if h3_result['statistic'] > 0 else \"negative\"\n",
    "    print(f\"\\n=> Statistically significant {direction} association detected.\")\n",
    "\n",
    "hypothesis_results.append({\n",
    "    \"hypothesis_id\": \"H3\",\n",
    "    \"outcome\": \"low_mood_freq\",\n",
    "    \"predictor\": \"compare_to_successful\",\n",
    "    \"test_used\": \"Spearman correlation\",\n",
    "    **h3_result\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H3 Plot: Binned bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Calculate mean low_mood_freq for each comparison level\n",
    "comparison_means = df.groupby(\"compare_to_successful\")[\"low_mood_freq\"].agg([\"mean\", \"std\", \"count\"])\n",
    "comparison_means[\"se\"] = comparison_means[\"std\"] / np.sqrt(comparison_means[\"count\"])\n",
    "\n",
    "x = comparison_means.index\n",
    "y = comparison_means[\"mean\"]\n",
    "yerr = comparison_means[\"se\"] * 1.96  # 95% CI\n",
    "\n",
    "bars = ax.bar(x, y, yerr=yerr, color=COLORS[\"secondary\"], edgecolor=\"white\", \n",
    "              capsize=5, error_kw={\"linewidth\": 2})\n",
    "\n",
    "ax.set_xlabel(\"Comparison to Successful People (1=Never, 5=Very Often)\")\n",
    "ax.set_ylabel(\"Mean Low Mood Frequency\")\n",
    "ax.set_title(f\"H3: Social Comparison vs Low Mood (rho={h3_result['statistic']:.2f})\")\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_ylim(0, 5)\n",
    "\n",
    "# Add sample sizes\n",
    "for i, (level, row) in enumerate(comparison_means.iterrows()):\n",
    "    ax.text(level, 0.2, f\"n={int(row['count'])}\", ha=\"center\", fontsize=9, color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"h3_comparison_vs_mood.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** There is a clear positive association between frequency of comparing oneself to successful people on social media and low mood frequency. Those who \"very often\" compare themselves report notably higher low mood on average. This aligns with research on social comparison theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H4: Higher seek_validation is associated with higher low_mood_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H4: Spearman correlation - seek_validation vs low_mood_freq\n",
    "h4_result = run_spearman_test(df, \"seek_validation\", \"low_mood_freq\")\n",
    "\n",
    "print(\"H4: Validation-seeking vs Low mood frequency\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test: Spearman correlation\")\n",
    "print(f\"n = {h4_result['n']}\")\n",
    "print(f\"Spearman rho = {h4_result['statistic']:.3f}\")\n",
    "print(f\"p-value = {h4_result['p_value']:.4e}\")\n",
    "print(f\"Effect size interpretation: {h4_result['interpretation']}\")\n",
    "\n",
    "if h4_result['p_value'] < 0.05:\n",
    "    direction = \"positive\" if h4_result['statistic'] > 0 else \"negative\"\n",
    "    print(f\"\\n=> Statistically significant {direction} association detected.\")\n",
    "\n",
    "hypothesis_results.append({\n",
    "    \"hypothesis_id\": \"H4\",\n",
    "    \"outcome\": \"low_mood_freq\",\n",
    "    \"predictor\": \"seek_validation\",\n",
    "    \"test_used\": \"Spearman correlation\",\n",
    "    **h4_result\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H4 Plot: Box plot of low_mood_freq by seek_validation level\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare data\n",
    "box_data = [df[df[\"seek_validation\"] == level][\"low_mood_freq\"].dropna().values \n",
    "            for level in [1, 2, 3, 4, 5]]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=[\"1\\n(Never)\", \"2\", \"3\", \"4\", \"5\\n(Very Often)\"], \n",
    "                patch_artist=True)\n",
    "\n",
    "# Style\n",
    "for patch in bp[\"boxes\"]:\n",
    "    patch.set_facecolor(COLORS[\"tertiary\"])\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Add means\n",
    "means = [np.mean(d) for d in box_data]\n",
    "ax.scatter(range(1, 6), means, color=COLORS[\"quaternary\"], marker=\"D\", s=50, zorder=3, label=\"Mean\")\n",
    "\n",
    "ax.set_xlabel(\"Validation-Seeking Frequency\")\n",
    "ax.set_ylabel(\"Low Mood Frequency (1-5)\")\n",
    "ax.set_title(f\"H4: Validation-Seeking vs Low Mood (rho={h4_result['statistic']:.2f})\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 5.5)\n",
    "\n",
    "# Add sample sizes\n",
    "for i, data in enumerate(box_data, 1):\n",
    "    ax.text(i, 0.7, f\"n={len(data)}\", ha=\"center\", fontsize=9, color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"h4_validation_vs_mood.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** Validation-seeking behaviour shows a moderate positive association with low mood frequency. Respondents who more frequently seek validation through social media features (likes, comments) also tend to report higher low mood frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H5: Higher restless_without_sm is associated with higher sleep_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5: Spearman correlation - restless_without_sm vs sleep_issues\n",
    "h5_result = run_spearman_test(df, \"restless_without_sm\", \"sleep_issues\")\n",
    "\n",
    "print(\"H5: Restlessness without SM vs Sleep issues\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test: Spearman correlation\")\n",
    "print(f\"n = {h5_result['n']}\")\n",
    "print(f\"Spearman rho = {h5_result['statistic']:.3f}\")\n",
    "print(f\"p-value = {h5_result['p_value']:.4e}\")\n",
    "print(f\"Effect size interpretation: {h5_result['interpretation']}\")\n",
    "\n",
    "if h5_result['p_value'] < 0.05:\n",
    "    direction = \"positive\" if h5_result['statistic'] > 0 else \"negative\"\n",
    "    print(f\"\\n=> Statistically significant {direction} association detected.\")\n",
    "\n",
    "hypothesis_results.append({\n",
    "    \"hypothesis_id\": \"H5\",\n",
    "    \"outcome\": \"sleep_issues\",\n",
    "    \"predictor\": \"restless_without_sm\",\n",
    "    \"test_used\": \"Spearman correlation\",\n",
    "    **h5_result\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5 Plot: Scatter with binned means\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Jittered scatter\n",
    "x = df[\"restless_without_sm\"].values + np.random.uniform(-0.15, 0.15, len(df))\n",
    "y = df[\"sleep_issues\"].values + np.random.uniform(-0.15, 0.15, len(df))\n",
    "ax.scatter(x, y, alpha=0.4, color=COLORS[\"primary\"], edgecolor=\"none\", s=40)\n",
    "\n",
    "# Binned means\n",
    "binned_means = df.groupby(\"restless_without_sm\")[\"sleep_issues\"].mean()\n",
    "ax.plot(binned_means.index, binned_means.values, color=COLORS[\"quaternary\"], \n",
    "        linewidth=3, marker=\"o\", markersize=10, label=\"Mean by level\")\n",
    "\n",
    "ax.set_xlabel(\"Restlessness Without Social Media (1-5)\")\n",
    "ax.set_ylabel(\"Sleep Issues (1-5)\")\n",
    "ax.set_title(f\"H5: Restlessness vs Sleep Issues (rho={h5_result['statistic']:.2f})\")\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"h5_restless_vs_sleep.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** There is a moderate positive association between restlessness when not using social media and sleep issues. This may reflect a pattern where those more \"dependent\" on social media also experience more disrupted sleep, though the direction of causality cannot be determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "results_df = pd.DataFrame(hypothesis_results)\n",
    "results_df[\"significant\"] = results_df[\"p_value\"] < 0.05\n",
    "\n",
    "# Reorder columns\n",
    "results_df = results_df[[\n",
    "    \"hypothesis_id\", \"outcome\", \"predictor\", \"test_used\", \"n\",\n",
    "    \"statistic\", \"p_value\", \"effect_size_name\", \"effect_size_value\", \n",
    "    \"interpretation\", \"significant\"\n",
    "]]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HYPOTHESIS TESTING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hypothesis results to CSV\n",
    "results_df.to_csv(reports_path / \"hypothesis_results.csv\", index=False)\n",
    "print(f\"Saved: {reports_path / 'hypothesis_results.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Segment Comparisons (Privacy-Safe)\n",
    "\n",
    "We examine patterns by age band and gender group, using aggregated categories to protect small-group privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check segment sizes for privacy\n",
    "print(\"Segment sizes (n < 10 flagged):\")\n",
    "print(\"\\nAge bands:\")\n",
    "age_counts = df[\"age_band\"].value_counts()\n",
    "for band, count in age_counts.items():\n",
    "    flag = \" [SMALL SAMPLE]\" if count < 10 else \"\"\n",
    "    print(f\"  {band}: {count}{flag}\")\n",
    "\n",
    "print(\"\\nGender (grouped):\")\n",
    "gender_counts = df[\"gender_grouped\"].value_counts()\n",
    "for gender, count in gender_counts.items():\n",
    "    flag = \" [SMALL SAMPLE]\" if count < 10 else \"\"\n",
    "    print(f\"  {gender}: {count}{flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low mood frequency by age band (box plot)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Filter out small samples and order age bands\n",
    "age_band_order = [\"<18\", \"18-24\", \"25-34\", \"35-44\", \"45+\"]\n",
    "valid_bands = [b for b in age_band_order if age_counts.get(b, 0) >= 10]\n",
    "\n",
    "box_data = [df[df[\"age_band\"] == band][\"low_mood_freq\"].dropna().values \n",
    "            for band in valid_bands]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=valid_bands, patch_artist=True)\n",
    "\n",
    "for patch in bp[\"boxes\"]:\n",
    "    patch.set_facecolor(COLORS[\"primary\"])\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Add means\n",
    "means = [np.mean(d) for d in box_data]\n",
    "ax.scatter(range(1, len(valid_bands)+1), means, color=COLORS[\"quaternary\"], \n",
    "           marker=\"D\", s=50, zorder=3, label=\"Mean\")\n",
    "\n",
    "ax.set_xlabel(\"Age Band\")\n",
    "ax.set_ylabel(\"Low Mood Frequency (1-5)\")\n",
    "ax.set_title(\"Low Mood Frequency by Age Band\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 5.5)\n",
    "\n",
    "# Sample sizes\n",
    "for i, (band, data) in enumerate(zip(valid_bands, box_data), 1):\n",
    "    ax.text(i, 0.7, f\"n={len(data)}\", ha=\"center\", fontsize=9, color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"segment_mood_by_age.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** Low mood frequency appears relatively consistent across age bands in this sample, with perhaps slightly higher variability in the youngest (<18) and oldest (45+) groups. The 18-24 age band dominates the sample, reflecting the survey's composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low mood frequency by gender (grouped, privacy-safe)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Only include groups with n >= 10\n",
    "valid_genders = [g for g in [\"Male\", \"Female\", \"Non-binary & Other\"] \n",
    "                 if gender_counts.get(g, 0) >= 10]\n",
    "\n",
    "box_data = [df[df[\"gender_grouped\"] == g][\"low_mood_freq\"].dropna().values \n",
    "            for g in valid_genders]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=valid_genders, patch_artist=True)\n",
    "\n",
    "for patch in bp[\"boxes\"]:\n",
    "    patch.set_facecolor(COLORS[\"secondary\"])\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "means = [np.mean(d) for d in box_data]\n",
    "ax.scatter(range(1, len(valid_genders)+1), means, color=COLORS[\"quaternary\"], \n",
    "           marker=\"D\", s=50, zorder=3, label=\"Mean\")\n",
    "\n",
    "ax.set_xlabel(\"Gender (Grouped)\")\n",
    "ax.set_ylabel(\"Low Mood Frequency (1-5)\")\n",
    "ax.set_title(\"Low Mood Frequency by Gender Group\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 5.5)\n",
    "\n",
    "for i, (gender, data) in enumerate(zip(valid_genders, box_data), 1):\n",
    "    ax.text(i, 0.7, f\"n={len(data)}\", ha=\"center\", fontsize=9, color=\"gray\")\n",
    "\n",
    "if len(valid_genders) < 3:\n",
    "    ax.text(0.5, 0.95, \"Note: Some groups excluded (n<10)\", \n",
    "            transform=ax.transAxes, fontsize=9, color=\"red\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path / \"segment_mood_by_gender.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this suggests:** Female respondents report slightly higher low mood frequency on average compared to male respondents, though distributions overlap substantially. The Non-binary & Other group is small (n<10) and excluded from this comparison for privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Key Findings, Limitations & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate EDA summary report\n",
    "summary_lines = [\n",
    "    \"# EDA Summary Report\",\n",
    "    \"\",\n",
    "    f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "    f\"**Dataset:** smmh_clean.csv (n={len(df)} social media users)\",\n",
    "    \"\",\n",
    "    \"## Key Findings\",\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "# Summarize significant findings\n",
    "sig_results = results_df[results_df[\"significant\"]]\n",
    "\n",
    "key_findings = [\n",
    "    f\"1. **Social comparison is strongly associated with low mood.** Respondents who frequently compare themselves to successful people on social media report higher low mood frequency (rho={results_df[results_df['hypothesis_id']=='H3']['statistic'].values[0]:.2f}, p<0.001).\",\n",
    "    \"\",\n",
    "    f\"2. **Purposeless scrolling correlates with low mood.** Those who use social media without specific purpose more often report higher low mood frequency (rho={results_df[results_df['hypothesis_id']=='H2']['statistic'].values[0]:.2f}, p<0.001).\",\n",
    "    \"\",\n",
    "    f\"3. **Validation-seeking behaviour shows a moderate association with low mood.** Respondents who more frequently seek validation through social media features also report higher low mood (rho={results_df[results_df['hypothesis_id']=='H4']['statistic'].values[0]:.2f}, p<0.001).\",\n",
    "    \"\",\n",
    "]\n",
    "summary_lines.extend(key_findings)\n",
    "\n",
    "summary_lines.extend([\n",
    "    \"## Notable Distributions\",\n",
    "    \"\",\n",
    "    \"### Social Media Usage Time\",\n",
    "    f\"- Most common: 'More than 5 hours' ({df['daily_time_band'].value_counts().iloc[0]} respondents, {df['daily_time_band'].value_counts().iloc[0]/len(df)*100:.0f}%)\",\n",
    "    f\"- Only {df[df['daily_time_band']=='Less than an Hour'].shape[0]} respondents ({df[df['daily_time_band']=='Less than an Hour'].shape[0]/len(df)*100:.0f}%) use SM for less than 1 hour/day\",\n",
    "    \"\",\n",
    "    \"### Platform Usage\",\n",
    "    f\"- YouTube: {df['platform_youtube'].sum()} ({df['platform_youtube'].mean()*100:.0f}%)\",\n",
    "    f\"- Facebook: {df['platform_facebook'].sum()} ({df['platform_facebook'].mean()*100:.0f}%)\",\n",
    "    f\"- Instagram: {df['platform_instagram'].sum()} ({df['platform_instagram'].mean()*100:.0f}%)\",\n",
    "    f\"- Average platforms per person: {df['platform_count'].mean():.1f}\",\n",
    "    \"\",\n",
    "    \"### Demographics\",\n",
    "    f\"- Dominated by 18-24 age band ({df[df['age_band']=='18-24'].shape[0]} respondents, {df[df['age_band']=='18-24'].shape[0]/len(df)*100:.0f}%)\",\n",
    "    f\"- Gender split: {df[df['gender_grouped']=='Female'].shape[0]} Female ({df[df['gender_grouped']=='Female'].shape[0]/len(df)*100:.0f}%), {df[df['gender_grouped']=='Male'].shape[0]} Male ({df[df['gender_grouped']=='Male'].shape[0]/len(df)*100:.0f}%)\",\n",
    "    \"\",\n",
    "    \"## Hypothesis Test Results\",\n",
    "    \"\",\n",
    "    \"| Hypothesis | Association | Effect Size | Significant? |\",\n",
    "    \"|------------|-------------|-------------|-------------|\",\n",
    "])\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    sig = \"Yes\" if row[\"significant\"] else \"No\"\n",
    "    summary_lines.append(\n",
    "        f\"| {row['hypothesis_id']}: {row['predictor']} -> {row['outcome']} | \"\n",
    "        f\"rho={row['statistic']:.2f} | {row['interpretation']} | {sig} |\"\n",
    "    )\n",
    "\n",
    "summary_lines.extend([\n",
    "    \"\",\n",
    "    \"## Limitations\",\n",
    "    \"\",\n",
    "    \"1. **Cross-sectional data:** Cannot determine causality. Associations may be bidirectional or confounded.\",\n",
    "    \"2. **Self-reported measures:** Subject to recall bias and social desirability effects.\",\n",
    "    \"3. **Sample composition:** Dominated by university students aged 18-24; findings may not generalise.\",\n",
    "    \"4. **Small subgroups:** Some demographic segments have small samples (e.g., Non-binary & Other group).\",\n",
    "    \"\",\n",
    "    \"## Next Steps (for Tableau/Streamlit)\",\n",
    "    \"\",\n",
    "    \"1. Create interactive filters for age_band, gender_grouped, daily_time_band\",\n",
    "    \"2. Build dashboard with key visualisations (platform usage, time distribution, correlations)\",\n",
    "    \"3. Add plain-English interpretation panels for non-technical users\",\n",
    "    \"4. Include prominent 'association ≠ causation' disclaimers\",\n",
    "    \"\",\n",
    "])\n",
    "\n",
    "# Save summary\n",
    "summary_text = \"\\n\".join(summary_lines)\n",
    "(reports_path / \"eda_summary.md\").write_text(summary_text)\n",
    "print(f\"Saved: {reports_path / 'eda_summary.md'}\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Findings (Plain English)\n",
    "\n",
    "1. **Social comparison matters most.** People who frequently compare themselves to \"successful\" others on social media tend to report feeling down more often. This was the strongest association we found.\n",
    "\n",
    "2. **Aimless scrolling is linked to low mood.** Respondents who use social media \"without a specific purpose\" more frequently also report higher low mood frequency. This suggests the *quality* of engagement may matter more than just time spent.\n",
    "\n",
    "3. **Validation-seeking shows a pattern.** Those who more often seek likes, comments, and other forms of validation tend to report more frequent low mood.\n",
    "\n",
    "### Important Caveat\n",
    "\n",
    "**These are associations, not causes.** We cannot say social media *causes* low mood. It's equally possible that people who feel down use social media differently, or that other factors (personality, life circumstances) influence both.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs Generated\n",
    "\n",
    "- `reports/eda_summary.md` — Summary of key findings\n",
    "- `reports/hypothesis_results.csv` — Statistical test results table\n",
    "- `reports/figures/` — All visualisations as PNG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated outputs\n",
    "print(\"\\nGenerated outputs:\")\n",
    "print(f\"  {reports_path / 'eda_summary.md'}\")\n",
    "print(f\"  {reports_path / 'hypothesis_results.csv'}\")\n",
    "print(f\"\\nFigures:\")\n",
    "for fig_file in sorted(figures_path.glob(\"*.png\")):\n",
    "    print(f\"  {fig_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2s1dwi5zwc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EDA NOTEBOOK TEST\n",
      "==================================================\n",
      "Data exists: True\n",
      "Loaded: 478 rows\n",
      "\n",
      "Hypothesis Tests:\n",
      "  H2 (purposeless->mood): rho=0.29, p=8.84e-11\n",
      "  H3 (compare->mood): rho=0.40, p=3.18e-20\n",
      "  H4 (validation->mood): rho=0.26, p=1.00e-08\n",
      "  H5 (restless->sleep): rho=0.16, p=4.31e-04\n",
      "\n",
      " All tests passed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup\n",
    "project_root = Path(\"/Users/giaaxa/social-media-mental-health\")\n",
    "data_path = project_root / \"data\" / \"processed\" / \"v1\" / \"smmh_clean.csv\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"EDA NOTEBOOK TEST\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Data exists: {data_path.exists()}\")\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[df[\"include_in_analysis\"] == True].copy()\n",
    "print(f\"Loaded: {len(df)} rows\")\n",
    "\n",
    "# Test hypothesis functions\n",
    "def run_spearman(df, v1, v2):\n",
    "    data = df[[v1, v2]].dropna()\n",
    "    rho, p = stats.spearmanr(data[v1], data[v2])\n",
    "    return rho, p\n",
    "\n",
    "# Run tests\n",
    "print(\"\\nHypothesis Tests:\")\n",
    "h2 = run_spearman(df, \"purposeless_use\", \"low_mood_freq\")\n",
    "print(f\"  H2 (purposeless->mood): rho={h2[0]:.2f}, p={h2[1]:.2e}\")\n",
    "\n",
    "h3 = run_spearman(df, \"compare_to_successful\", \"low_mood_freq\")\n",
    "print(f\"  H3 (compare->mood): rho={h3[0]:.2f}, p={h3[1]:.2e}\")\n",
    "\n",
    "h4 = run_spearman(df, \"seek_validation\", \"low_mood_freq\")\n",
    "print(f\"  H4 (validation->mood): rho={h4[0]:.2f}, p={h4[1]:.2e}\")\n",
    "\n",
    "h5 = run_spearman(df, \"restless_without_sm\", \"sleep_issues\")\n",
    "print(f\"  H5 (restless->sleep): rho={h5[0]:.2f}, p={h5[1]:.2e}\")\n",
    "\n",
    "print(\"\\n All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3r4rjvpxj0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures...\n",
      "  platform_usage.png\n",
      "  wellbeing_distributions.png\n",
      "  time_distribution.png\n",
      "  correlation_heatmap.png\n",
      "\n",
      "Basic figures generated!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paths\n",
    "reports_path = project_root / \"reports\"\n",
    "figures_path = reports_path / \"figures\"\n",
    "figures_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COLORS = {'primary': '#2E86AB', 'secondary': '#A23B72', 'tertiary': '#F18F01', 'quaternary': '#C73E1D'}\n",
    "plt.rcParams.update({'figure.figsize': (10, 6), 'axes.spines.top': False, 'axes.spines.right': False})\n",
    "\n",
    "# Column definitions\n",
    "LIKERT_COLS = [\"purposeless_use\", \"distracted_when_busy\", \"restless_without_sm\",\n",
    "               \"easily_distracted\", \"worries_bother\", \"difficulty_concentrating\",\n",
    "               \"compare_to_successful\", \"comparison_feelings\", \"seek_validation\",\n",
    "               \"low_mood_freq\", \"interest_fluctuation\", \"sleep_issues\"]\n",
    "PLATFORM_COLS = [\"platform_facebook\", \"platform_twitter\", \"platform_instagram\",\n",
    "                 \"platform_youtube\", \"platform_snapchat\", \"platform_discord\",\n",
    "                 \"platform_reddit\", \"platform_pinterest\", \"platform_tiktok\"]\n",
    "WELLBEING_COLS = [\"low_mood_freq\", \"sleep_issues\", \"worries_bother\", \"difficulty_concentrating\"]\n",
    "BEHAVIOUR_COLS = [\"purposeless_use\", \"distracted_when_busy\", \"restless_without_sm\",\n",
    "                  \"compare_to_successful\", \"seek_validation\"]\n",
    "TIME_BAND_ORDER = [\"Less than an Hour\", \"Between 1 and 2 hours\", \"Between 2 and 3 hours\",\n",
    "                   \"Between 3 and 4 hours\", \"Between 4 and 5 hours\", \"More than 5 hours\"]\n",
    "\n",
    "df[\"daily_time_band\"] = pd.Categorical(df[\"daily_time_band\"], categories=TIME_BAND_ORDER, ordered=True)\n",
    "\n",
    "print(\"Generating figures...\")\n",
    "\n",
    "# Platform usage\n",
    "fig, ax = plt.subplots()\n",
    "pcts = [(col.replace(\"platform_\", \"\").title(), df[col].mean()*100) for col in PLATFORM_COLS]\n",
    "pcts.sort(key=lambda x: x[1], reverse=True)\n",
    "ax.barh([p[0] for p in pcts], [p[1] for p in pcts], color=COLORS['primary'])\n",
    "ax.set_xlabel(\"% of Respondents\"); ax.set_title(\"Platform Usage\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"platform_usage.png\", dpi=150); plt.close()\n",
    "print(\"  platform_usage.png\")\n",
    "\n",
    "# Wellbeing distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "for ax, col in zip(axes.flatten(), WELLBEING_COLS):\n",
    "    counts = df[col].value_counts().sort_index()\n",
    "    ax.bar(counts.index, counts.values, color=COLORS['secondary'])\n",
    "    ax.set_title(col.replace(\"_\", \" \").title()); ax.set_xlabel(\"1-5\"); ax.set_ylabel(\"Count\")\n",
    "    ax.axvline(df[col].mean(), color=COLORS['quaternary'], linestyle='--', lw=2)\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"wellbeing_distributions.png\", dpi=150); plt.close()\n",
    "print(\"  wellbeing_distributions.png\")\n",
    "\n",
    "# Time distribution\n",
    "fig, ax = plt.subplots()\n",
    "tc = df[\"daily_time_band\"].value_counts().reindex(TIME_BAND_ORDER)\n",
    "ax.bar(range(6), tc.values, color=COLORS['tertiary'])\n",
    "ax.set_xticks(range(6)); ax.set_xticklabels([\"<1h\", \"1-2h\", \"2-3h\", \"3-4h\", \"4-5h\", \">5h\"])\n",
    "ax.set_xlabel(\"Daily Time\"); ax.set_ylabel(\"Count\"); ax.set_title(\"Daily SM Time Distribution\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"time_distribution.png\", dpi=150); plt.close()\n",
    "print(\"  time_distribution.png\")\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_cols = BEHAVIOUR_COLS + WELLBEING_COLS\n",
    "corr = df[corr_cols].corr(method=\"spearman\")\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(corr.values, cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(len(corr_cols))); ax.set_yticks(range(len(corr_cols)))\n",
    "labels = [c.replace(\"_\", \" \")[:10] for c in corr_cols]\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\"); ax.set_yticklabels(labels)\n",
    "for i in range(len(corr_cols)):\n",
    "    for j in range(len(corr_cols)):\n",
    "        ax.text(j, i, f\"{corr.values[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=7)\n",
    "plt.colorbar(im, ax=ax); ax.set_title(\"Correlation Matrix\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"correlation_heatmap.png\", dpi=150); plt.close()\n",
    "print(\"  correlation_heatmap.png\")\n",
    "\n",
    "print(\"\\nBasic figures generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tx1h4dldpn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hypothesis figures...\n",
      "  h1_low_mood_by_time_band.png\n",
      "  h2_purposeless_vs_mood.png\n",
      "  h3_comparison_vs_mood.png\n",
      "  h4_validation_vs_mood.png\n",
      "  h5_restless_vs_sleep.png\n",
      "  segment_mood_by_age.png\n",
      "  segment_mood_by_gender.png\n",
      "\n",
      "All hypothesis figures generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate hypothesis test figures\n",
    "print(\"Generating hypothesis figures...\")\n",
    "\n",
    "# H1 box plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "box_data = [df[df[\"daily_time_band\"] == b][\"low_mood_freq\"].dropna().values for b in TIME_BAND_ORDER]\n",
    "bp = ax.boxplot(box_data, tick_labels=[\"<1h\", \"1-2h\", \"2-3h\", \"3-4h\", \"4-5h\", \">5h\"], patch_artist=True)\n",
    "for p in bp[\"boxes\"]: p.set_facecolor(COLORS['primary']); p.set_alpha(0.7)\n",
    "means = [np.mean(d) for d in box_data]\n",
    "ax.scatter(range(1,7), means, color=COLORS['quaternary'], marker='D', s=50, zorder=3)\n",
    "ax.set_xlabel(\"Daily Time\"); ax.set_ylabel(\"Low Mood (1-5)\"); ax.set_title(\"H1: Low Mood by Time Spent\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"h1_low_mood_by_time_band.png\", dpi=150); plt.close()\n",
    "print(\"  h1_low_mood_by_time_band.png\")\n",
    "\n",
    "# H2 scatter\n",
    "fig, ax = plt.subplots()\n",
    "np.random.seed(42)\n",
    "x = df[\"purposeless_use\"] + np.random.uniform(-0.15, 0.15, len(df))\n",
    "y = df[\"low_mood_freq\"] + np.random.uniform(-0.15, 0.15, len(df))\n",
    "ax.scatter(x, y, alpha=0.4, color=COLORS['primary'])\n",
    "bm = df.groupby(\"purposeless_use\")[\"low_mood_freq\"].mean()\n",
    "ax.plot(bm.index, bm.values, color=COLORS['quaternary'], lw=3, marker='o', ms=10)\n",
    "ax.set_xlabel(\"Purposeless Use\"); ax.set_ylabel(\"Low Mood\"); ax.set_title(f\"H2: rho=0.29\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"h2_purposeless_vs_mood.png\", dpi=150); plt.close()\n",
    "print(\"  h2_purposeless_vs_mood.png\")\n",
    "\n",
    "# H3 bars\n",
    "fig, ax = plt.subplots()\n",
    "cm = df.groupby(\"compare_to_successful\")[\"low_mood_freq\"].agg([\"mean\", \"std\", \"count\"])\n",
    "cm[\"se\"] = cm[\"std\"] / np.sqrt(cm[\"count\"])\n",
    "ax.bar(cm.index, cm[\"mean\"], yerr=cm[\"se\"]*1.96, color=COLORS['secondary'], capsize=5)\n",
    "ax.set_xlabel(\"Compare to Successful\"); ax.set_ylabel(\"Mean Low Mood\"); ax.set_title(f\"H3: rho=0.40\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"h3_comparison_vs_mood.png\", dpi=150); plt.close()\n",
    "print(\"  h3_comparison_vs_mood.png\")\n",
    "\n",
    "# H4 box plot\n",
    "fig, ax = plt.subplots()\n",
    "box_data = [df[df[\"seek_validation\"] == l][\"low_mood_freq\"].dropna().values for l in [1,2,3,4,5]]\n",
    "bp = ax.boxplot(box_data, tick_labels=[\"1\", \"2\", \"3\", \"4\", \"5\"], patch_artist=True)\n",
    "for p in bp[\"boxes\"]: p.set_facecolor(COLORS['tertiary']); p.set_alpha(0.7)\n",
    "ax.set_xlabel(\"Validation-Seeking\"); ax.set_ylabel(\"Low Mood\"); ax.set_title(f\"H4: rho=0.26\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"h4_validation_vs_mood.png\", dpi=150); plt.close()\n",
    "print(\"  h4_validation_vs_mood.png\")\n",
    "\n",
    "# H5 scatter\n",
    "fig, ax = plt.subplots()\n",
    "x = df[\"restless_without_sm\"] + np.random.uniform(-0.15, 0.15, len(df))\n",
    "y = df[\"sleep_issues\"] + np.random.uniform(-0.15, 0.15, len(df))\n",
    "ax.scatter(x, y, alpha=0.4, color=COLORS['primary'])\n",
    "bm = df.groupby(\"restless_without_sm\")[\"sleep_issues\"].mean()\n",
    "ax.plot(bm.index, bm.values, color=COLORS['quaternary'], lw=3, marker='o', ms=10)\n",
    "ax.set_xlabel(\"Restlessness\"); ax.set_ylabel(\"Sleep Issues\"); ax.set_title(f\"H5: rho=0.16\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"h5_restless_vs_sleep.png\", dpi=150); plt.close()\n",
    "print(\"  h5_restless_vs_sleep.png\")\n",
    "\n",
    "# Segment plots\n",
    "age_counts = df[\"age_band\"].value_counts()\n",
    "valid_ages = [b for b in [\"<18\", \"18-24\", \"25-34\", \"35-44\", \"45+\"] if age_counts.get(b, 0) >= 10]\n",
    "fig, ax = plt.subplots()\n",
    "box_data = [df[df[\"age_band\"] == b][\"low_mood_freq\"].dropna().values for b in valid_ages]\n",
    "bp = ax.boxplot(box_data, tick_labels=valid_ages, patch_artist=True)\n",
    "for p in bp[\"boxes\"]: p.set_facecolor(COLORS['primary']); p.set_alpha(0.7)\n",
    "ax.set_xlabel(\"Age Band\"); ax.set_ylabel(\"Low Mood\"); ax.set_title(\"Low Mood by Age\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"segment_mood_by_age.png\", dpi=150); plt.close()\n",
    "print(\"  segment_mood_by_age.png\")\n",
    "\n",
    "gender_counts = df[\"gender_grouped\"].value_counts()\n",
    "valid_genders = [g for g in [\"Male\", \"Female\"] if gender_counts.get(g, 0) >= 10]\n",
    "fig, ax = plt.subplots()\n",
    "box_data = [df[df[\"gender_grouped\"] == g][\"low_mood_freq\"].dropna().values for g in valid_genders]\n",
    "bp = ax.boxplot(box_data, tick_labels=valid_genders, patch_artist=True)\n",
    "for p in bp[\"boxes\"]: p.set_facecolor(COLORS['secondary']); p.set_alpha(0.7)\n",
    "ax.set_xlabel(\"Gender\"); ax.set_ylabel(\"Low Mood\"); ax.set_title(\"Low Mood by Gender\")\n",
    "plt.tight_layout(); plt.savefig(figures_path / \"segment_mood_by_gender.png\", dpi=150); plt.close()\n",
    "print(\"  segment_mood_by_gender.png\")\n",
    "\n",
    "print(\"\\nAll hypothesis figures generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vcl211rh7y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: hypothesis_results.csv\n",
      "hypothesis_id       outcome             predictor            test_used   n  statistic      p_value effect_size_name  effect_size_value interpretation  significant\n",
      "           H1 low_mood_freq       daily_time_band       Kruskal-Wallis 478  53.696778 2.419158e-10  epsilon_squared           0.112572       moderate         True\n",
      "           H2 low_mood_freq       purposeless_use Spearman correlation 478   0.290960 8.843277e-11     Spearman rho           0.290960          small         True\n",
      "           H3 low_mood_freq compare_to_successful Spearman correlation 478   0.404315 3.178347e-20     Spearman rho           0.404315       moderate         True\n",
      "           H4 low_mood_freq       seek_validation Spearman correlation 478   0.258320 1.001629e-08     Spearman rho           0.258320          small         True\n",
      "           H5  sleep_issues   restless_without_sm Spearman correlation 478   0.160385 4.312696e-04     Spearman rho           0.160385          small         True\n",
      "\n",
      "Saved: eda_summary.md\n"
     ]
    }
   ],
   "source": [
    "# Save hypothesis results CSV and EDA summary\n",
    "\n",
    "# Helper functions for full results\n",
    "def interpret_rho(rho):\n",
    "    if abs(rho) < 0.10: return \"negligible\"\n",
    "    elif abs(rho) < 0.30: return \"small\"\n",
    "    elif abs(rho) < 0.50: return \"moderate\"\n",
    "    else: return \"large\"\n",
    "\n",
    "def interpret_epsilon(eps):\n",
    "    if eps < 0.01: return \"negligible\"\n",
    "    elif eps < 0.06: return \"small\"\n",
    "    elif eps < 0.14: return \"moderate\"\n",
    "    else: return \"large\"\n",
    "\n",
    "# Run all hypothesis tests\n",
    "results = []\n",
    "\n",
    "# H1 - Kruskal-Wallis\n",
    "data = df[[\"daily_time_band\", \"low_mood_freq\"]].dropna()\n",
    "groups = [g[\"low_mood_freq\"].values for _, g in data.groupby(\"daily_time_band\", observed=True)]\n",
    "h_stat, p_val = stats.kruskal(*groups)\n",
    "eps_sq = h_stat / (len(data) - 1)\n",
    "results.append({\n",
    "    \"hypothesis_id\": \"H1\", \"outcome\": \"low_mood_freq\", \"predictor\": \"daily_time_band\",\n",
    "    \"test_used\": \"Kruskal-Wallis\", \"n\": len(data), \"statistic\": h_stat, \"p_value\": p_val,\n",
    "    \"effect_size_name\": \"epsilon_squared\", \"effect_size_value\": eps_sq,\n",
    "    \"interpretation\": interpret_epsilon(eps_sq)\n",
    "})\n",
    "\n",
    "# H2-H5 - Spearman correlations\n",
    "for hid, v1, v2 in [\n",
    "    (\"H2\", \"purposeless_use\", \"low_mood_freq\"),\n",
    "    (\"H3\", \"compare_to_successful\", \"low_mood_freq\"),\n",
    "    (\"H4\", \"seek_validation\", \"low_mood_freq\"),\n",
    "    (\"H5\", \"restless_without_sm\", \"sleep_issues\")\n",
    "]:\n",
    "    data = df[[v1, v2]].dropna()\n",
    "    rho, p = stats.spearmanr(data[v1], data[v2])\n",
    "    results.append({\n",
    "        \"hypothesis_id\": hid, \"outcome\": v2, \"predictor\": v1,\n",
    "        \"test_used\": \"Spearman correlation\", \"n\": len(data), \"statistic\": rho, \"p_value\": p,\n",
    "        \"effect_size_name\": \"Spearman rho\", \"effect_size_value\": rho,\n",
    "        \"interpretation\": interpret_rho(rho)\n",
    "    })\n",
    "\n",
    "# Create DataFrame and save\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df[\"significant\"] = results_df[\"p_value\"] < 0.05\n",
    "results_df = results_df[[\"hypothesis_id\", \"outcome\", \"predictor\", \"test_used\", \"n\",\n",
    "                         \"statistic\", \"p_value\", \"effect_size_name\", \"effect_size_value\",\n",
    "                         \"interpretation\", \"significant\"]]\n",
    "results_df.to_csv(reports_path / \"hypothesis_results.csv\", index=False)\n",
    "print(\"Saved: hypothesis_results.csv\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save EDA summary\n",
    "h1, h2, h3, h4, h5 = [results_df[results_df[\"hypothesis_id\"]==f\"H{i}\"].iloc[0] for i in range(1,6)]\n",
    "\n",
    "summary = f\"\"\"# EDA Summary Report\n",
    "\n",
    "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "**Dataset:** smmh_clean.csv (n={len(df)} social media users)\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **Social comparison is strongly associated with low mood.** Respondents who frequently compare themselves to successful people on social media report higher low mood frequency (rho={h3['statistic']:.2f}, p<0.001).\n",
    "\n",
    "2. **Purposeless scrolling correlates with low mood.** Those who use social media without specific purpose more often report higher low mood frequency (rho={h2['statistic']:.2f}, p<0.001).\n",
    "\n",
    "3. **Validation-seeking behaviour shows a moderate association with low mood.** Respondents who more frequently seek validation through social media features also report higher low mood (rho={h4['statistic']:.2f}, p<0.001).\n",
    "\n",
    "## Hypothesis Test Results\n",
    "\n",
    "| ID | Predictor | Outcome | Statistic | Effect Size | Significant? |\n",
    "|----|-----------|---------|-----------|-------------|--------------|\n",
    "| H1 | daily_time_band | low_mood_freq | H={h1['statistic']:.1f} | {h1['interpretation']} | {'Yes' if h1['significant'] else 'No'} |\n",
    "| H2 | purposeless_use | low_mood_freq | rho={h2['statistic']:.2f} | {h2['interpretation']} | Yes |\n",
    "| H3 | compare_to_successful | low_mood_freq | rho={h3['statistic']:.2f} | {h3['interpretation']} | Yes |\n",
    "| H4 | seek_validation | low_mood_freq | rho={h4['statistic']:.2f} | {h4['interpretation']} | Yes |\n",
    "| H5 | restless_without_sm | sleep_issues | rho={h5['statistic']:.2f} | {h5['interpretation']} | Yes |\n",
    "\n",
    "## Notable Distributions\n",
    "\n",
    "- **Daily time:** Most common is \"More than 5 hours\" ({df[df['daily_time_band']=='More than 5 hours'].shape[0]} respondents)\n",
    "- **Platforms:** YouTube ({df['platform_youtube'].mean()*100:.0f}%), Facebook ({df['platform_facebook'].mean()*100:.0f}%), Instagram ({df['platform_instagram'].mean()*100:.0f}%)\n",
    "- **Demographics:** 18-24 age band dominates ({df[df['age_band']=='18-24'].shape[0]} respondents, {df[df['age_band']=='18-24'].shape[0]/len(df)*100:.0f}%)\n",
    "\n",
    "## Limitations\n",
    "\n",
    "1. **Cross-sectional data:** Cannot determine causality. Associations may be bidirectional.\n",
    "2. **Self-reported measures:** Subject to recall bias and social desirability effects.\n",
    "3. **Sample composition:** Dominated by university students aged 18-24.\n",
    "4. **Small subgroups:** Non-binary & Other group excluded from gender comparison (n<10).\n",
    "\n",
    "## Next Steps (Tableau/Streamlit)\n",
    "\n",
    "1. Create interactive filters for age_band, gender_grouped, daily_time_band\n",
    "2. Build dashboard with key visualisations\n",
    "3. Add plain-English interpretation panels\n",
    "4. Include prominent \"association ≠ causation\" disclaimers\n",
    "\"\"\"\n",
    "\n",
    "(reports_path / \"eda_summary.md\").write_text(summary)\n",
    "print(\"\\nSaved: eda_summary.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nfi8dqana3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "NOTEBOOK EXECUTION COMPLETE\n",
      "==================================================\n",
      "\n",
      "Reports:\n",
      "  eda_summary.md\n",
      "  etl_report.md\n",
      "  hypothesis_results.csv\n",
      "\n",
      "Figures:\n",
      "  correlation_heatmap.png\n",
      "  h1_low_mood_by_time_band.png\n",
      "  h2_purposeless_vs_mood.png\n",
      "  h3_comparison_vs_mood.png\n",
      "  h4_validation_vs_mood.png\n",
      "  h5_restless_vs_sleep.png\n",
      "  platform_usage.png\n",
      "  segment_mood_by_age.png\n",
      "  segment_mood_by_gender.png\n",
      "  time_distribution.png\n",
      "  wellbeing_distributions.png\n",
      "\n",
      " All outputs generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# List all generated files\n",
    "print(\"=\" * 50)\n",
    "print(\"NOTEBOOK EXECUTION COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nReports:\")\n",
    "for f in sorted(reports_path.glob(\"*\")):\n",
    "    if f.is_file():\n",
    "        print(f\"  {f.name}\")\n",
    "\n",
    "print(\"\\nFigures:\")\n",
    "for f in sorted(figures_path.glob(\"*.png\")):\n",
    "    print(f\"  {f.name}\")\n",
    "\n",
    "print(\"\\n All outputs generated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
